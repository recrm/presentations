{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What follows is a quick scan of the technologies and problems that come up when putting a machine learning model to use.\n",
    "\n",
    "I by no means expect everyone to follow along with everything. So I'll be making this notebook available to anyone who wants it for reference in the future.\n",
    "\n",
    "For now, just think of it as way to start getting familiar with various technologies and how they fit together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning\n",
    "====\n",
    "\n",
    "In just a few lines of code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using sample data included in the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Read in Data\n",
    "bunch = load_iris()\n",
    "data = bunch[\"data\"]\n",
    "targets = bunch[\"target\"]\n",
    "feature_names = bunch[\"feature_names\"]\n",
    "target_names = bunch[\"target_names\"]\n",
    "\n",
    "print(feature_names)\n",
    "print(data[:10])\n",
    "print()\n",
    "print(target_names)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train, let's simplify the problem a bit by converting the data into a boolean classifier instead of a multiclass classifier. This means we will only be interested in one type of flower instead of three. All this classifier will do is tell us if it is a \"virginica\" specimen or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = np.array([1 if i == 2 else 0 for i in targets])\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(data, targets)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(data_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on testing dataset\n",
    "results = model.predict(data_test)\n",
    "\n",
    "# Calculate score of model\n",
    "score = accuracy_score(labels_test, results)\n",
    "print(\"Model Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that everything? Are we done?\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of data science and machine learning tutorials and talks end there. Kaggle (a regular machine learning competition) notoriously only cares about that last number. Higher is better. Highest wins the prize. It's not uncommon for ML notebooks to contain hundreds of lines of code, and still end with that number.\n",
    "\n",
    "Job done, right?\n",
    "\n",
    "As a data engineer the job has only begun. The first thing your boss is going ask when he sees that above number is \"How can I sell it?\". So let's talk about what it takes to actually use this for something useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Persistance\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing we need to do is save our model to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joblib is a fairly basic utility library. It doesn't do any one particular thing, instead it has helpers for a lot of different little things. Scikit-learn didn't bother making their own serializer and instead recomends we use the one built into joblib because it handles large amounts of numeric data exceptionally well (and models are at their core just a giant bundle of numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, \"model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing for a basic api.\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create a model management object. This object will manage our model and make sure it is loaded when our server goes up. We don't want our server doing an expensive hard drive read every time someone makes a call to our api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    def __init__(self, path_to_model):\n",
    "        self.model = joblib.load(path_to_model)\n",
    "\n",
    "    def score(self, data):\n",
    "        return self.model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well, we cannot send numpy arrays (scikit-learn's native format) over the internet. So instead we are going to send and recieve everything through json. \n",
    "\n",
    "We will need a function to translate the json we recieve to the array of numbers our model requires.\n",
    "\n",
    "We will also need a function for the reverse transformation, so that we can send the prediction back to our user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_numpy(data):\n",
    "    # Note how are keys list is hard coded. This will be important later.\n",
    "    keys = [\n",
    "        'sepal length (cm)',\n",
    "        'sepal width (cm)',\n",
    "        'petal length (cm)',\n",
    "        'petal width (cm)'\n",
    "    ]\n",
    "\n",
    "    return np.array([data[key] for key in keys]).reshape(1, -1) # scikit learn is very particular, it wants a matrix not an array. So we have to resize it.\n",
    "\n",
    "def numpy_to_dict(array):\n",
    "    return {\n",
    "        \"prediction\": \"virginica\" if int(array[0]) == 1 else \"not virginica\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, now let's put all of this together and build our endpoint function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need our manager to get instantiated when the server goes up, not when we call the endpoint.\n",
    "model_manager = ModelManager(\"model.pkl\")\n",
    "\n",
    "def api_endpoint(data):\n",
    "    array = dict_to_numpy(data)\n",
    "    result = model_manager.score(array)\n",
    "\n",
    "    return numpy_to_dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 'not virginica'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_request = {\n",
    "    \"sepal length (cm)\": 5,\n",
    "    \"sepal width (cm)\": 2,\n",
    "    \"petal length (cm)\": 2,\n",
    "    \"petal width (cm)\": 1\n",
    "}\n",
    "\n",
    "api_endpoint(sample_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up an actual API\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are numerous web application frameworks in python. The most famous of which is django. Django is super powerful and allows us to build extreamly complicated web based applications in python. However, it is also super complicated and way to much power for our purposes. Instead we are going to be using flask.\n",
    "\n",
    "Flask is a lightweight web application framework that is designed to be super easy to use. It will allow us to stand up a relativly simple application in only a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, flask won't work inside of jupyter notebook, so let's switch to an executable file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waitress is another web library. It is the actual web server that will be hosting our flask app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(see api.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the api\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make calls to our api we will make use of another library called requests. Requests is a very large library, but we only need it to make http requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\"http://0.0.0.0:8080/score\", json=sample_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 'not virginica'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An issue with versions\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So everything is all fine and well, until someone does something unspeakable.\n",
    "\n",
    "They update the version of some of our libraries...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PKL don't actually save the model. It only saves the data stored on that model. Usually this is enough to reproduce the trained model exactly, but only if the sklearn version is the same as when it was trained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's break some stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call to our server still worked. But sklearn gave us some fairly serious warnings. We shouldn't ignore them. We got lucky this time, but sometimes things won't allways work.\n",
    "\n",
    "(Note: I upgraded from scikit-learn 0.22.2 to latest. Had I upgraded from 0.20.0 to latest everything would have broken. This was a very serious actual issue that needed solving)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can't update scikit-learn. But you will probobly notice that on a more complicated system we won't be able to upgrade anything. Scikit learn was kind enough to give us a warning, but other technologies aren't as kind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, this means two things are true. \n",
    "\n",
    "1) We can never update our software.\n",
    "\n",
    "2) Two models trained on different computers cannot simultanously run on the same system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Containers to the rescue!!\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As my final trick I am going to wrap my entire python environment into a docker container. \n",
    "\n",
    "But first we need to save our python environment using the python default package manager pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip3 freeze > requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(See Dockerfile for final result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following are command line functions that likely won't work in jupyter.\n",
    "# I am recording them here anyway for reference.\n",
    "\n",
    "# build the server.\n",
    "os.system(\"docker build -t ml_server .\")\n",
    "os.system(\"docker run -itp 8080:8080 ml_server\") # Note, we have to explicity open ports to docker containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we test our new docker server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 'not virginica'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.post(\"http://0.0.0.0:8080/score\", json=sample_request)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All is well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least until we start trying to sync code at train time and inference time.\n",
    "\n",
    "But that is a nightmare for another day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kevin-project",
   "language": "python",
   "name": "kevin-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
